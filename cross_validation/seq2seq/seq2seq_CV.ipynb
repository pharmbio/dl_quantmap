{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import custom script CNN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(device(type='cuda'), True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import gc\n",
    "import glob\n",
    "import sys\n",
    "import random\n",
    "import string\n",
    "import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import codecs\n",
    "from SmilesPE.pretokenizer import atomwise_tokenizer\n",
    "from SmilesPE.pretokenizer import kmer_tokenizer\n",
    "from SmilesPE.learner import *\n",
    "from SmilesPE.tokenizer import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "supp_script_path = '../../supp_scripts/'\n",
    "sys.path.append(supp_script_path) # path for support scripts folder\n",
    "import supp_utils as su\n",
    "\n",
    "# set gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device,torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# To remove rdkit warning\n",
    "from rdkit import RDLogger\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_filename = \"parameters_seq2seq.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole section is to read parameters from the parameter file\n",
    "parameter_file = open(parameter_filename)\n",
    "parameters = json.load(parameter_file)\n",
    "parameter_file.close()\n",
    "\n",
    "# User inputs\n",
    "input_file_train = parameters[\"input_file_train\"] # input file\n",
    "input_file_test = parameters[\"input_file_test\"] # input file\n",
    "\n",
    "trial = parameters[\"trial\"] # setting False saves the output files else not saved\n",
    "\n",
    "if not trial:\n",
    "    run_folder = parameters[\"run_folder\"]\n",
    "\n",
    "gpu_id = int(parameters[\"gpu_id\"])\n",
    "if gpu_id != None:\n",
    "    device = \"cuda:\" + str(gpu_id)\n",
    "else:\n",
    "    gpu_id = 0\n",
    "    \n",
    "# Removing data with lower distribution\n",
    "enable_label_cutoff = parameters[\"label_cutoff\"][\"enable_label_cutoff\"]\n",
    "lower_label_count_cutoff = int(parameters[\"label_cutoff\"][\"lower_label_count_cutoff\"])\n",
    "upper_label_count_cutoff = int(parameters[\"label_cutoff\"][\"upper_label_count_cutoff\"])\n",
    "\n",
    "# Sequence length to be considered\n",
    "lower_cutoff = int(parameters[\"sequence_length_cutoff\"][\"lower_cutoff\"])\n",
    "upper_cutoff = int(parameters[\"sequence_length_cutoff\"][\"upper_cutoff\"])\n",
    "\n",
    "k_fold_value = int(parameters[\"k_fold_value\"]) # Number of folds\n",
    "\n",
    "label_wise_augmentation = parameters[\"augmentation\"][\"label_wise_augmentation\"]\n",
    "number_of_augmentation = int(parameters[\"augmentation\"][\"number_of_augmentation\"])\n",
    "iteration = int(parameters[\"augmentation\"][\"iteration\"])\n",
    "\n",
    "tokenization = parameters[\"tokens\"][\"tokenization\"] # options are SPE,atomwise,vocab_file\n",
    "if tokenization == \"SPE\":\n",
    "    spe_min_frequency = int(parameters[\"tokens\"][\"spe_min_frequency\"])\n",
    "sos_eos_tokens = parameters[\"tokens\"][\"sos_eos_tokens\"]\n",
    "\n",
    "use_vocab_file = parameters[\"vocab_file\"][\"use_vocab_file\"]\n",
    "if use_vocab_file:\n",
    "    vocab_file_path = parameters[\"vocab_file\"][\"vocab_file_path\"]\n",
    "\n",
    "#####################\n",
    "# Network parameters#\n",
    "#####################\n",
    "load_model = parameters[\"pretrained_model\"][\"load_model\"]\n",
    "#if load_model is True set the path for pretrained_model_path\n",
    "pretrained_model_path = parameters[\"pretrained_model\"][\"pretrained_model_path\"]\n",
    "\n",
    "hidden_size = int(parameters[\"lstm_parameters\"][\"hidden_size\"])\n",
    "num_layers = int(parameters[\"lstm_parameters\"][\"num_layers\"])\n",
    "en_embedding_size = int(parameters[\"lstm_parameters\"][\"en_embedding_size\"])\n",
    "en_dropout = float(parameters[\"lstm_parameters\"][\"en_dropout\"])\n",
    "\n",
    "fc_size = int(parameters[\"fc_layer_parameters\"][\"fc_size\"])\n",
    "fc_dropout = float(parameters[\"fc_layer_parameters\"][\"fc_dropout\"]) # fully connected layer dropout\n",
    "\n",
    "epochs = int(parameters[\"network_parameters\"][\"epochs\"])\n",
    "batch_size = int(parameters[\"network_parameters\"][\"batch_size\"])\n",
    "learning_rate = float(parameters[\"network_parameters\"][\"learning_rate\"])\n",
    "enable_class_weight = parameters[\"network_parameters\"][\"enable_class_weight\"]\n",
    "\n",
    "Number_of_workers = int(parameters[\"Number_of_workers\"])\n",
    "\n",
    "##################\n",
    "### Do not edit###\n",
    "##################\n",
    "if not trial:\n",
    "    os.system(\"mkdir \" + str(run_folder))\n",
    "\n",
    "atomwise_tokenization = False\n",
    "train_SPE = False\n",
    "\n",
    "if tokenization == \"SPE\":\n",
    "    train_SPE = True\n",
    "elif tokenization == \"atomwise\":\n",
    "    atomwise_tokenization = True\n",
    "else:\n",
    "    atomwise_tokenization = True\n",
    "    print (\"Tokenization not provided/incorrect. Using atomwise tokenization\")\n",
    "\n",
    "if not trial:\n",
    "    network_parameter_output = open(str(run_folder) + \"/network_parameters.txt\",\"w\",1)\n",
    "    for parameter in parameters:\n",
    "        network_parameter_output.write(str(parameter) + \" = \" + str(parameters[parameter]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq2seq network, only with the perceiver connected to the fully connected layer for classification\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size) #,padding_idx=0)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p,batch_first=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (N,seq_length) where N is batch size\n",
    "          \n",
    "        pack_pad_list = x.shape[0] - (np.array(x.cpu()) == 0).sum(0)\n",
    "        \n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape: (N,seq_length, embedding_size)\n",
    "        \n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedding, \n",
    "                                                                lengths = torch.as_tensor(pack_pad_list, dtype=torch.int64).cpu(),\n",
    "                                                                batch_first = False,\n",
    "                                                                enforce_sorted=False\n",
    "                                                               )\n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        \n",
    "        return hidden[hidden.shape[0]-1]\n",
    "        \n",
    "class FC_layer(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size,p):\n",
    "        super(FC_layer, self).__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size, fc_size)   \n",
    "        self.fc2 = nn.Linear(fc_size, output_size)\n",
    "\n",
    "    def forward(self, hidden):\n",
    "        fc_out = self.dropout(self.lrelu((self.fc1(hidden))))\n",
    "        fc_out = self.fc2(fc_out)\n",
    "        \n",
    "        return fc_out\n",
    "\n",
    "class seq2seq(nn.Module):\n",
    "    def __init__(self, encoder, fc_layer):\n",
    "        super(seq2seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.fc_layer = fc_layer\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
    "        batch_size = source.shape[1]\n",
    "\n",
    "        hidden = self.encoder(source)\n",
    "        outputs = self.fc_layer(hidden)        \n",
    "        #outputs = self.softmax(outputs)\n",
    "        \n",
    "        return outputs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading train_valid and test splits from the file and make it to a dataframe\n",
    "smiles_label_test = {line.split()[0]:line.split()[1] for line in open(input_file_test,\"r\").readlines()}\n",
    "smiles_label_test = dict(sorted(smiles_label_test.items(), key=lambda item: item[1]))\n",
    "\n",
    "smiles_label_train = {line.split()[0]:line.split()[1] for line in open(input_file_train,\"r\").readlines()}\n",
    "smiles_label_train = dict(sorted(smiles_label_train.items(), key=lambda item: item[1]))\n",
    "\n",
    "train_valid_df = su.dict_to_label(smiles_label_train)\n",
    "train_valid_df = train_valid_df\n",
    "test_df = su.dict_to_label(smiles_label_test)\n",
    "test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "def plot_loss_accuracy(train_list,valid_list,filename):\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n",
    "    plt.plot(train_list, label='Training')\n",
    "    plt.plot(valid_list, label='Validation')\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n",
    "    \n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model on loss and accuracy\n",
      "LOSS train: 0.051777192113351904  val: 0.2041056089103222 \tACCU train: 0.97265625  val: 0.953125\n",
      "LOSS train: 0.018968748116296612  val: 0.21160579919815065 \tACCU train: 0.9904513888888888  val: 0.959375\n",
      "Final model\n",
      "LOSS train: 0.001352951567645909  val: 0.37693544626235964 \tACCU train: 1.0  val: 0.946875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                   \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2db33d244317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_accu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq2seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/akshai_other/quantmap/git/git_edit/supp_scripts/seq2seq.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_dl, device)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;31m# Back prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/molpmofit/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/molpmofit/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for fold in range(k_fold_value):\n",
    "    \n",
    "    if not trial:\n",
    "        log_file = open(str(run_folder) + \"/model_\" + str(fold) + \".txt\",\"w\")\n",
    "        model_output_name = str(run_folder) + \"/model_\" + str(fold) + \".pth\"\n",
    "    \n",
    "    piece_count = fold + 1\n",
    "    # create train and valid dataframe for the current fold\n",
    "    train,valid,piece_count = su.CV.get_K_fold_cv_data(train_valid_df,k_fold_value,piece_count,shuffle_output=True)\n",
    "    train_df = pd.DataFrame(train.items(),columns=[\"Smiles\", \"Label\"]).sample(frac=1).reset_index(drop=True)\n",
    "    valid_df = pd.DataFrame(valid.items(),columns=[\"Smiles\", \"Label\"]).sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # calculate class_weight\n",
    "    if enable_class_weight:\n",
    "        class_weight = torch.FloatTensor(su.get_class_weight(train_df)).cuda(gpu_id)\n",
    "        if not trial:\n",
    "            log_file.write(\"Class weight for loss (balancing weights)= \" + str(class_weight) + \"\\n\")\n",
    "            \n",
    "    if not trial:\n",
    "        log_file.write(\"Class distribution before augmentation\\n\")\n",
    "        log_file.write(\"Train data\\n\")\n",
    "        log_file.write(str(train_df.groupby('Label').count()) + \"\\n\")\n",
    "        log_file.write(\"Valid data\\n\")\n",
    "        log_file.write(str(valid_df.groupby('Label').count()) + \"\\n\")\n",
    "        log_file.write(\"Test data\\n\")\n",
    "        log_file.write(str(test_df.groupby('Label').count()) + \"\\n\")\n",
    "    \n",
    "    \n",
    "    # Data augmentation\n",
    "    if number_of_augmentation > 0:\n",
    "        if label_wise_augmentation:\n",
    "            # label wise augmentation list calculation\n",
    "            train_augmentation_list = su.get_augmentation_list(train_df,number_of_augmentation)\n",
    "            number_of_augmentation_train = train_augmentation_list\n",
    "            \n",
    "            valid_augmentation_list = su.get_augmentation_list(valid_df,number_of_augmentation)\n",
    "            number_of_augmentation_valid = valid_augmentation_list\n",
    "            \n",
    "            #if fold == 0:\n",
    "            test_augmentation_list = su.get_augmentation_list(test_df,number_of_augmentation)\n",
    "            number_of_augmentation_test = test_augmentation_list\n",
    "\n",
    "        else:   \n",
    "            number_of_augmentation_train = number_of_augmentation\n",
    "            number_of_augmentation_valid = number_of_augmentation\n",
    "            #if fold == 0:\n",
    "            number_of_augmentation_test = number_of_augmentation\n",
    "                \n",
    "        train_data = su.smiles_augmentation(train_df,\n",
    "                                            N_rounds=number_of_augmentation_train,\n",
    "                                            iteration=iteration,\n",
    "                                            data_set_type=\"train_data\",\n",
    "                                            Number_of_workers=Number_of_workers)     \n",
    "            \n",
    "        valid_data = su.smiles_augmentation(valid_df,\n",
    "                                            N_rounds=number_of_augmentation_valid,\n",
    "                                            iteration=iteration,\n",
    "                                            data_set_type=\"valid_data\",\n",
    "                                            Number_of_workers=Number_of_workers)\n",
    "        #if fold == 0:\n",
    "        test_data = su.smiles_augmentation(test_df,\n",
    "                                            N_rounds=number_of_augmentation_test,\n",
    "                                            iteration=iteration,\n",
    "                                            data_set_type=\"test_data\",\n",
    "                                            Number_of_workers=Number_of_workers)\n",
    "        \n",
    "        if not trial:\n",
    "            log_file.write(\"number of augmentation = \" + str(number_of_augmentation) + \"\\n\")\n",
    "            log_file.write(\"Class distribution after augmentation\\n\")\n",
    "            log_file.write(\"Train data\\n\")\n",
    "            log_file.write(str(train_data.groupby('Label').count()) + \"\\n\")\n",
    "            log_file.write(\"Valid data\\n\")\n",
    "            log_file.write(str(valid_data.groupby('Label').count()) + \"\\n\")\n",
    "            log_file.write(\"Test data\\n\")\n",
    "            log_file.write(str(valid_data.groupby('Label').count()) + \"\\n\")\n",
    "    else:\n",
    "        train_data = train_df\n",
    "        valid_data = valid_df\n",
    "        #if fold == 0:\n",
    "        test_data = test_df\n",
    "    \n",
    "    \n",
    "    # train spe tokenization\n",
    "    if train_SPE:\n",
    "        all_smiles = train_data['Smiles'].to_list()\n",
    "        token_path = str(run_folder) + \"/tokens_\" + str(fold) + \".txt\"\n",
    "        su.seq2seq.train_spe_tokenizer(all_smiles,token_path,min_frequency=spe_min_frequency,augmentation=0)\n",
    "    \n",
    "    \n",
    "    # create or use vocab\n",
    "    if use_vocab_file:\n",
    "        word_index,index_word = su.seq2seq.read_vocab_file(vocab_file_path)\n",
    "        token_path = \"\"\n",
    "    else:\n",
    "        output_vocab_path = str(run_folder) + \"/vocab\" + str(fold) + \".txt\"\n",
    "        if train_SPE:\n",
    "            word_index,index_word = su.seq2seq.create_vocab_file_spe(train_data,\n",
    "                                                                     token_path,\n",
    "                                                                     Number_of_workers,\n",
    "                                                                     output_vocab_path,\n",
    "                                                                     sos_eos_tokens)\n",
    "        else:\n",
    "            token_path = \"\"\n",
    "            word_index,index_word = su.seq2seq.create_vocab_file_atomwise(train_data,\n",
    "                                                                          Number_of_workers,\n",
    "                                                                          output_vocab_path,\n",
    "                                                                          sos_eos_tokens)\n",
    "    \n",
    "    \n",
    "    # convert to tokens\n",
    "    x_train,y_train= su.seq2seq.convert_smiles_to_tokens(train_data,\n",
    "                                                         lower_cutoff=lower_cutoff,\n",
    "                                                         upper_cutoff=upper_cutoff,\n",
    "                                                         Number_of_workers=Number_of_workers,\n",
    "                                                         token_path=token_path,\n",
    "                                                         sos_eos_tokens=sos_eos_tokens,\n",
    "                                                         tokenization=tokenization)\n",
    "    \n",
    "    x_valid,y_valid= su.seq2seq.convert_smiles_to_tokens(valid_data,\n",
    "                                                       lower_cutoff=lower_cutoff,\n",
    "                                                       upper_cutoff=upper_cutoff,\n",
    "                                                       Number_of_workers=Number_of_workers,\n",
    "                                                       token_path=token_path,\n",
    "                                                       sos_eos_tokens=sos_eos_tokens,\n",
    "                                                       tokenization=tokenization)\n",
    "    \n",
    "    #if fold == 0:\n",
    "    x_test,y_test= su.seq2seq.convert_smiles_to_tokens(test_data,\n",
    "                                                       lower_cutoff=lower_cutoff,\n",
    "                                                       upper_cutoff=upper_cutoff,\n",
    "                                                       Number_of_workers=Number_of_workers,\n",
    "                                                       token_path=token_path,\n",
    "                                                       sos_eos_tokens=sos_eos_tokens,\n",
    "                                                       tokenization=tokenization)\n",
    "    \n",
    "    if not trial:\n",
    "        log_file.write(\"Training : Data point = \" + str(len(train_df)) + \"\\n\")\n",
    "        log_file.write(\"Training : Data point within cutoff criteria = \" + str(len(x_train)) + \"\\n\")\n",
    "        log_file.write(\"Valid : Data point = \" + str(len(valid_df)) + \"\\n\")\n",
    "        log_file.write(\"Valid : Data point within cutoff criteria = \" + str(len(x_valid)) + \"\\n\")\n",
    "        log_file.write(\"Test : Data point = \" + str(len(test_df)) + \"\\n\")\n",
    "        log_file.write(\"Test : Data point within cutoff criteria = \" + str(len(x_test)) + \"\\n\")\n",
    "    \n",
    "    \n",
    "    # convert to index\n",
    "    x_train_indexed = su.seq2seq.convert_token_to_index_multi(x_train,word_index)\n",
    "    x_valid_indexed = su.seq2seq.convert_token_to_index_multi(x_valid,word_index)\n",
    "    #if fold == 0:\n",
    "    x_test_indexed = su.seq2seq.convert_token_to_index_multi(x_test,word_index)\n",
    "    \n",
    "    # create iterator\n",
    "    train_iterator =  su.seq2seq.make_bucket_iterator(x_train_indexed,y_train,batch_size,device)\n",
    "    valid_iterator =  su.seq2seq.make_bucket_iterator(x_valid_indexed,y_valid,batch_size,device)\n",
    "    #if fold == 0:\n",
    "    test_iterator =  su.seq2seq.make_bucket_iterator(x_test_indexed,y_test,batch_size,device)\n",
    "        \n",
    "    # Build model\n",
    "    input_size_encoder = len(word_index)\n",
    "    output_size = len(set(y_train))\n",
    "\n",
    "    encoder_net = Encoder(\n",
    "        input_size_encoder, \n",
    "        en_embedding_size, \n",
    "        hidden_size, \n",
    "        num_layers, \n",
    "        en_dropout).to(device)\n",
    "\n",
    "\n",
    "    fc_layer = FC_layer(hidden_size, output_size,fc_dropout).to(device)\n",
    "    \n",
    "    model = seq2seq(encoder_net, fc_layer).to(device)\n",
    "    \n",
    "    if load_model: # Rework has to be done for this\n",
    "        model.load_state_dict(torch.load(pretrained_model_path), strict=False)\n",
    "\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay=1e-4)\n",
    "    if enable_class_weight:\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weight)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    \n",
    "    # Training the network\n",
    "    # List to store values\n",
    "    train_loss_list = []\n",
    "    train_accu_list = []\n",
    "    val_loss_list = []\n",
    "    val_accu_list = []\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    train_f1_list = []\n",
    "    valid_f1_list = []\n",
    "    \n",
    "    # model training\n",
    "    loop = tqdm.tqdm(range(epochs), total=epochs,leave=False)\n",
    "    for epoch in loop:\n",
    "\n",
    "        train_loss, train_accu = su.seq2seq.train(model,criterion,optimizer,train_iterator,device)\n",
    "        val_loss,val_accu = su.seq2seq.validate(model,criterion,valid_iterator,device)\n",
    "        \n",
    "        \n",
    "        # For callback\n",
    "        # Callback saves the best model based on the below priority\n",
    "        # validation loss --> validation accuracy--> training loss--> training accuracy\n",
    "        if epoch == 0:\n",
    "            torch.save(model.state_dict(), model_output_name)\n",
    "            saved_model_id = epoch + 1\n",
    "\n",
    "        if epoch != 0:\n",
    "            current_epoch_values = [train_loss, train_accu,val_loss,val_accu]\n",
    "            previous_epoch_values = [train_loss_list,train_accu_list,val_loss_list,val_accu_list]\n",
    "            if su.callback(current_epoch_values,previous_epoch_values,model,model_output_name):\n",
    "                model_copy = copy.deepcopy(model)\n",
    "                saved_model_id = epoch + 1\n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_accu_list.append(train_accu)\n",
    "        val_loss_list.append(val_loss)\n",
    "        val_accu_list.append(val_accu)\n",
    "        \n",
    "        if not trial:\n",
    "            log_file.write(str(epoch+1) + \"\\t\" + str(train_loss) + \"\\t\" + str(val_loss) + \"\\t\" + str(train_accu) + \"\\t\" + str(val_accu)  + \"\\n\")\n",
    "        loop.set_description(\"LOSS train:\" + str(train_loss) + \" val:\" + str(val_loss) + \" \\tACCU train:\" + str(train_accu) + \" val:\" + str(val_accu))\n",
    "        \n",
    "    torch.save(model_copy.state_dict(), model_output_name)\n",
    "    \n",
    "    plot_loss_accuracy(train_accu_list,val_accu_list,str(run_folder) + \"/accuracy_\" + str(fold) + \".png\")\n",
    "    plot_loss_accuracy(train_loss_list,val_loss_list,str(run_folder) + \"/loss_\" + str(fold) + \".png\")\n",
    "    \n",
    "    log_file.write(\"\\nChosen model = epoch number \" + str(saved_model_id))\n",
    "    \n",
    "    \n",
    "    # Re-initializing the model for getting statistics for all the three sets of data for the current fold\n",
    "    model = seq2seq(encoder_net, fc_layer).to(device)\n",
    "    model.load_state_dict(torch.load(model_output_name), strict=True)\n",
    "    model.to(device)\n",
    "    \n",
    "    if not trial:# classification report and confusion matrix plot\n",
    "        loss,accuracy,prediction_list = su.seq2seq.test(model,criterion,train_iterator,device)\n",
    "        image_name = str(run_folder) + \"/train_\" + str(fold) + \"_cm.png\"\n",
    "        report = su.confustion_matrix(prediction_list,image_name)\n",
    "        log_file.write(\"\\n\\n\\nTrain data : Accu-\" + str(accuracy) + \"\\tLoss-\" + str(loss) + \"\\n\")\n",
    "        log_file.write(\"Train data report \\n-\" + str(report) + \"\\n\\n\\n\\n\\n\")\n",
    "    \n",
    "        loss,accuracy,prediction_list = su.seq2seq.test(model,criterion,valid_iterator,device)\n",
    "        image_name = str(run_folder) + \"/valid_\" + str(fold) + \"_cm.png\"\n",
    "        report = su.confustion_matrix(prediction_list,image_name)\n",
    "        log_file.write(\"\\n\\n\\nValid data : Accu-\" + str(accuracy) + \"\\tLoss-\" + str(loss) + \"\\n\")\n",
    "        log_file.write(\"Valid data report \\n-\" + str(report) + \"\\n\\n\\n\\n\\n\")\n",
    "        \n",
    "        loss,accuracy,prediction_list = su.seq2seq.test(model,criterion,test_iterator,device)\n",
    "        image_name = str(run_folder) + \"/test_\" + str(fold) + \"_cm.png\"\n",
    "        report = su.confustion_matrix(prediction_list,image_name)\n",
    "        log_file.write(\"\\n\\n\\nTest data : Accu-\" + str(accuracy) + \"\\tLoss-\" + str(loss) + \"\\n\")\n",
    "        log_file.write(\"Test data report \\n-\" + str(report) + \"\\n\\n\\n\\n\\n\")\n",
    "        \n",
    "    log_file.close()\n",
    "    \n",
    "    if fold == 0 and not trial:\n",
    "        network_parameter_output.write(\"model = \" + str(model) + \"\\n\")\n",
    "        network_parameter_output.close()\n",
    "    \n",
    "    # best validation loss\n",
    "    index1 = val_loss_list.index(sorted(val_loss_list)[0]) # index of least loss\n",
    "    index2 = val_accu_list.index(sorted(val_accu_list)[-1]) # index of highest accuracy\n",
    "    print (\"Best model on loss and accuracy\")\n",
    "    print (\"LOSS train:\",train_loss_list[index1],\" val:\",val_loss_list[index1], \"\\tACCU train:\",train_accu_list[index1],\" val:\",val_accu_list[index1])\n",
    "    print (\"LOSS train:\",train_loss_list[index2],\" val:\",val_loss_list[index2], \"\\tACCU train:\",train_accu_list[index2],\" val:\",val_accu_list[index2])\n",
    "    print (\"Final model\")\n",
    "    print (\"LOSS train:\",train_loss,\" val:\",val_loss, \"\\tACCU train:\",train_accu,\" val:\",val_accu)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molpmofit",
   "language": "python",
   "name": "molpmofit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
