{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import sys\n",
    "import random\n",
    "from random import sample\n",
    "import string\n",
    "import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import codecs\n",
    "from SmilesPE.pretokenizer import atomwise_tokenizer\n",
    "from SmilesPE.pretokenizer import kmer_tokenizer\n",
    "from SmilesPE.learner import *\n",
    "from SmilesPE.tokenizer import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supp script path\n",
    "sys.path.append('')\n",
    "import supp_utils as su\n",
    "\n",
    "# set gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device,torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_threshold = 0.005\n",
    "cid_smiles_file = \"cid_smiles_sanitized_canonical.txt\" # CID-SMILES information for the datapoints obtained from quantmap data\n",
    "\n",
    "cid_cluster_filename = \"cid_cluster_\" + str(distance_threshold) + \".txt\"\n",
    "node_details_filename = \"clustering_details_\" + str(distance_threshold) + \".csv\"\n",
    "cid_order_list = list(map(lambda x:int(x),open(\"cid_order_file.txt\",\"r\").readlines()))\n",
    "cluster_distance_filename = \"cluster_distance_\" + str(distance_threshold) + \".csv\"\n",
    "subset_folder = \"subset_data/\"\n",
    "support_above_folder = \"cluster_support_above_100/\"\n",
    "cluster_distance_output_filename = support_above_folder + \"cluster_distance_\" + str(distance_threshold) + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cid_cluster_file(input_filename):\n",
    "    with open(input_filename,\"r\") as f:\n",
    "        cid_cluster = {}\n",
    "        for entry in f.readlines():\n",
    "            cid_cluster[int(entry.split()[0])] = int(entry.split()[1])\n",
    "    \n",
    "    return (cid_cluster)\n",
    "\n",
    "def read_cluster_distance_file(input_filename):\n",
    "    cluster_distance = []\n",
    "    with open(input_filename) as f:\n",
    "        for i,entry in enumerate(f.readlines()):\n",
    "            if i != 0:\n",
    "                entry_split = entry.split(\",\")\n",
    "                dicts = {\"cluster1\":int(entry_split[0]),\"cluster2\":int(entry_split[1]),\"distance\":float(entry_split[2])}\n",
    "                cluster_distance.append(dicts)\n",
    "    \n",
    "    return (cluster_distance)\n",
    "\n",
    "cid_cluster_all = cid_cluster_file(cid_cluster_filename)\n",
    "cluster_distance = read_cluster_distance_file(cluster_distance_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose cids with support more than specified\n",
    "cluster_lower_threshold = 100\n",
    "cluster_cids_all = {cluster_id:[] for cluster_id in list(map(int,set(list(cid_cluster_all.values()))))}\n",
    "for cid in cid_cluster_all:\n",
    "    cluster_cids_all[cid_cluster_all[cid]].append(cid)\n",
    "    \n",
    "cluster_cids = {}\n",
    "for cluster in cluster_cids_all:\n",
    "    if len(cluster_cids_all[cluster]) >= cluster_lower_threshold:\n",
    "        cluster_cids[cluster] = cluster_cids_all[cluster]\n",
    "        \n",
    "cid_cluster = {}\n",
    "for cid in cid_cluster_all:\n",
    "    if cid_cluster_all[cid] in cluster_cids:\n",
    "        cid_cluster[cid] = cid_cluster_all[cid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reassign_cluster_id(cid_cluster_dict,cluster_distance=None,output_path=\"\",addon=\"\"):\n",
    "    # Getting and reassigning cid_cluster dict and writing the output\n",
    "    all_clusters = sorted(list(set(list(cid_cluster_dict.values()))))\n",
    "    \n",
    "    reassign_dict = {}\n",
    "    for i,cluster in enumerate(all_clusters):\n",
    "        reassign_dict[cluster] = i\n",
    "    \n",
    "    reassigned_cid_cluster_dict = {}\n",
    "    for cid in cid_cluster_dict:\n",
    "        reassigned_cid_cluster_dict[cid] = reassign_dict[cid_cluster_dict[cid]]\n",
    "    \n",
    "    with open(output_path + cid_cluster_filename[:-4] + str(addon) + \".txt\",\"w\") as of:\n",
    "        for cid in reassigned_cid_cluster_dict:\n",
    "            of.write(str(cid) + \" \" + str(reassigned_cid_cluster_dict[cid]) + \"\\n\")\n",
    "    \n",
    "    \n",
    "    if not cluster_distance is None:\n",
    "        # Getting and reassigning cluster_distance dict and writing the output\n",
    "        with open(output_path + cluster_distance_filename[:-4] + str(addon) + \".csv\",\"w\") as of:\n",
    "            for dicts in cluster_distance:\n",
    "                cluster1 = str(reassign_dict[dicts[\"cluster1\"]])\n",
    "                cluster2 = str(reassign_dict[dicts[\"cluster2\"]])\n",
    "                distance = str(dicts[\"distance\"])\n",
    "                of.write(cluster1 + \",\" + cluster2 + \",\" + distance + \"\\n\")\n",
    "\n",
    "reassign_cluster_id(cid_cluster,cluster_distance,support_above_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_cluster = cid_cluster_file(support_above_folder + cid_cluster_filename)\n",
    "cluster_distance = read_cluster_distance_file(support_above_folder + cluster_distance_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_smiles_cluster_file(cid_smiles_file,cid_cluster_dict,output_filename,path):\n",
    "    cid_smiles = {int(entry.split()[0]):entry.split()[1] for entry in open(cid_smiles_file,\"r\").readlines()}\n",
    "    \n",
    "    non_found_cid_smiles = []\n",
    "    \n",
    "    with open(path + output_filename,\"w\") as of:\n",
    "        for cid in cid_cluster_dict:\n",
    "            try:\n",
    "                of.write(str(cid_smiles[cid]) + \" \" + str(cid_cluster_dict[cid]) + \"\\n\")\n",
    "            except:\n",
    "                non_found_cid_smiles.append(cid)\n",
    "    return non_found_cid_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_found_cid_smiles = write_smiles_cluster_file(cid_smiles_file,cid_cluster,\"smiles_cluster_sanitized_\" + str(distance_threshold) + \".txt\",support_above_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get distance between clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(node_details_filename,\"r\") as f:\n",
    "    node_details = [] \n",
    "    for i,entry in enumerate(f.readlines()):\n",
    "        if i != 0:\n",
    "            x = entry.split(\",\")\n",
    "            node_details.append({'node_id': int(x[0]), 'left': int(x[1]), 'right': int(x[2]), 'distance' : float(x[3])})\n",
    "            \n",
    "            \n",
    "cluster_count = list(cid_cluster_all.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster frequency distribution\n",
    "x = cluster_count\n",
    "plt.hist(x, density=False, bins=100)  # density=False would make counts\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Cluster number');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cid_positions_in_node(node):\n",
    "    \n",
    "    if node in node_cids:\n",
    "        return node_cids[node]\n",
    "        \n",
    "    cids = []\n",
    "    for dicts in node_details:\n",
    "        if dicts[\"node_id\"] == node:\n",
    "            left_node = dicts[\"left\"]\n",
    "            right_node = dicts[\"right\"]\n",
    "            not_found = False\n",
    "            break\n",
    "        not_found = True\n",
    "        \n",
    "    if left_node < total_samples:\n",
    "        cid = cid_order_list[left_node]\n",
    "        if cid in cid_cluster:\n",
    "            cids.append(cid)\n",
    "    else:\n",
    "        if left_node not in node_cids:\n",
    "            found_cids = find_cid_positions_in_node(left_node)\n",
    "            cids.extend(found_cids)\n",
    "            node_cids[left_node] = found_cids\n",
    "        else:\n",
    "            cids.extend(node_cids[left_node])\n",
    "        \n",
    "    if right_node < total_samples:\n",
    "        cid = cid_order_list[right_node]\n",
    "        if cid in cid_cluster:\n",
    "            cids.append(cid)\n",
    "    else:\n",
    "        if right_node not in node_cids:\n",
    "            found_cids =  find_cid_positions_in_node(right_node)\n",
    "            cids.extend(found_cids)\n",
    "            node_cids[right_node] = found_cids\n",
    "        else:\n",
    "            cids.extend(node_cids[right_node])\n",
    "    \n",
    "    output_cids = []\n",
    "    already_present_cluster = []\n",
    "    for cid in cids: \n",
    "        if cid_cluster[cid] not in already_present_cluster:\n",
    "            output_cids.append(cid)\n",
    "            already_present_cluster.append(cid_cluster[cid])\n",
    "\n",
    "    return (output_cids)\n",
    "\n",
    "def get_cluster_distance_two_cids(left_cids,right_cids,distance):\n",
    "    for left_cid in left_cids:\n",
    "        for right_cid in right_cids:\n",
    "            if str(left_cid) + \"_\" + str(right_cid) not in already_found_cids and str(right_cid) + \"_\" + str(left_cid) not in already_found_cids:    \n",
    "                left_cluster, right_cluster = cid_cluster[left_cid],cid_cluster[right_cid]\n",
    "                if str(left_cluster) + \"_\" + str(right_cluster) not in already_found_clusters and \\\n",
    "                str(right_cluster) + \"_\" + str(left_cluster) not in already_found_clusters:\n",
    "                    cluster_distance.append({\"cluster1\":left_cluster,\"cluster2\":right_cluster,\"distance\":distance})\n",
    "                    already_found_clusters.append(str(left_cluster) + \"_\" + str(right_cluster))\n",
    "                    already_found_cids.append(str(left_cid) + \"_\" + str(right_cid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_order = {}\n",
    "for cid in cid_order_list:\n",
    "    if cid in cid_cluster:\n",
    "        cid_order[cid] = True\n",
    "    else:\n",
    "        cid_order[cid] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_clusters = len(cluster_cids_all)\n",
    "total_samples = len(cid_cluster_all)\n",
    "\n",
    "all_nodes = []\n",
    "for dicts in node_details:\n",
    "    all_nodes.append(dicts[\"node_id\"])\n",
    "    \n",
    "node_cids = {}\n",
    "loop = tqdm.tqdm(all_nodes,total=len(all_nodes),leave=False)\n",
    "for node in loop:\n",
    "    if node not in node_cids:\n",
    "        node_cids[node] = find_cid_positions_in_node(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusters with one support\n",
    "one_list = []\n",
    "for lists in (list(node_cids.values())):\n",
    "    one_list.extend(lists)\n",
    "    \n",
    "one_cluster = []\n",
    "for cid in set(one_list):\n",
    "    one_cluster.append(cid_cluster[cid])\n",
    "\n",
    "print (len(set(one_cluster)),len(cid_cluster),len(set(one_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_found_clusters = []\n",
    "cluster_distance = []\n",
    "already_found_cids = []\n",
    "node_details_inverted = node_details[::-1]\n",
    "\n",
    "loop = tqdm.tqdm(node_details_inverted,total=len(node_details_inverted),leave=False)\n",
    "for dicts in loop:\n",
    "    distance = dicts[\"distance\"]\n",
    "    if distance > distance_threshold:\n",
    "        left_node = dicts[\"left\"]\n",
    "        right_node = dicts[\"right\"]\n",
    "        \n",
    "        if left_node > total_samples:\n",
    "            left_cids = node_cids[left_node]\n",
    "            left_condition = True\n",
    "        else:\n",
    "            left_cids = [cid_order_list[left_node]]\n",
    "            left_condition = cid_order[left_cids[0]]\n",
    "            \n",
    "        if right_node > total_samples:\n",
    "            right_cids = node_cids[right_node]\n",
    "            right_condition = True\n",
    "        else:\n",
    "            right_cids = [cid_order_list[right_node]]\n",
    "            right_condition = cid_order[right_cids[0]]\n",
    "            \n",
    "        if left_condition and right_condition and len(left_cids) > 0 and len(right_cids) > 0:\n",
    "            output_clusters = get_cluster_distance_two_cids(left_cids,right_cids,distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open(cluster_distance_output_filename,\"w\")\n",
    "outfile.write(\"cluster1,cluster2,distance\\n\")\n",
    "for dicts in cluster_distance:\n",
    "    outfile.write(str(dicts[\"cluster1\"]) + \",\" + str(dicts[\"cluster2\"]) + \",\" + str(dicts[\"distance\"]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of clusters for pilot runs (subset data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_five_clusters = []\n",
    "distance_list = []\n",
    "cluster_of_interst = 1\n",
    "for entry in cluster_distance:\n",
    "    if entry[\"cluster1\"] == cluster_of_interst or entry[\"cluster2\"] == cluster_of_interst:\n",
    "        distance_list.append(entry[\"distance\"])\n",
    "\n",
    "distance_list = sorted(distance_list)[:5]\n",
    "count = 0\n",
    "for entry in cluster_distance:\n",
    "    if entry[\"cluster1\"] == cluster_of_interst or entry[\"cluster2\"] == cluster_of_interst:\n",
    "        if entry[\"distance\"] in distance_list and count <= 3:\n",
    "            first_five_clusters.append(entry[\"cluster1\"])\n",
    "            first_five_clusters.append(entry[\"cluster2\"])\n",
    "            print (entry[\"distance\"])\n",
    "            count += 1\n",
    "first_five_clusters = sorted(list(set(first_five_clusters)))\n",
    "print (first_five_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_lower_distane_clusters = []\n",
    "  \n",
    "cluster_lower_distance_list = sorted([float(entry[\"distance\"]) for entry in cluster_distance])[:5]\n",
    "\n",
    "for entry in cluster_distance:\n",
    "    if entry[\"distance\"] in cluster_lower_distance_list and len(set(second_lower_distane_clusters)) < 5:\n",
    "        second_lower_distane_clusters.append(entry[\"cluster1\"])\n",
    "        second_lower_distane_clusters.append(entry[\"cluster2\"])\n",
    "        print (entry[\"distance\"] )\n",
    "second_lower_distane_clusters = sorted(list(set(second_lower_distane_clusters)))[:5]\n",
    "print (second_lower_distane_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_between_two_clusters(input_cluster1,input_cluster2):\n",
    "    for entry in cluster_distance:\n",
    "        if (entry[\"cluster1\"] == input_cluster1 or entry[\"cluster2\"] == input_cluster1) and \\\n",
    "            (entry[\"cluster1\"] == input_cluster2 or entry[\"cluster2\"] == input_cluster2):\n",
    "            print (entry[\"distance\"])\n",
    "    \n",
    "def farthest_cluster(input_cluster):\n",
    "    largest_distance = 0\n",
    "    for entry in cluster_distance:\n",
    "        if entry[\"cluster1\"] == input_cluster or entry[\"cluster2\"] == input_cluster:\n",
    "            if entry[\"distance\"] > largest_distance:\n",
    "                largest_distance = entry[\"distance\"]\n",
    "    \n",
    "    output_clusters = []\n",
    "    for entry in cluster_distance:\n",
    "        if (entry[\"cluster1\"] == input_cluster or entry[\"cluster2\"] == input_cluster) and entry[\"distance\"] == largest_distance:\n",
    "            if entry[\"cluster1\"] != input_cluster:\n",
    "                output_clusters.append(entry[\"cluster1\"])\n",
    "            if entry[\"cluster2\"] != input_cluster:\n",
    "                output_clusters.append(entry[\"cluster2\"])\n",
    "    return (output_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farthest_clusters_to_first_two_sets = []\n",
    "for entry in first_five_clusters + second_lower_distane_clusters:\n",
    "    farthest_clusters_to_first_two_sets.extend(farthest_cluster(entry))\n",
    "    \n",
    "farthest_clusters_to_first_two_sets = sorted(list(set(farthest_clusters_to_first_two_sets)))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cluster_selection = []\n",
    "selected_cluster_from_three = list(set(first_five_clusters + second_lower_distane_clusters + farthest_clusters_to_first_two_sets))\n",
    "remaining_count = 20 - len(selected_cluster_from_three)\n",
    "\n",
    "while remaining_count > 0:\n",
    "    sampled_cluster = sample(list(set(list(cid_cluster.values()))),1)[0]\n",
    "    if sampled_cluster not in selected_cluster_from_three and sampled_cluster not in random_cluster_selection:\n",
    "        random_cluster_selection.append(sampled_cluster)\n",
    "        remaining_count -= 1\n",
    "print (\"Randomly chosen \" + str(20 - (len(first_five_clusters) + len(second_lower_distane_clusters) + len(farthest_clusters_to_first_two_sets))) + \" cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(selected_cluster_from_three)),len(selected_cluster_from_three)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_clusters = random_cluster_selection + selected_cluster_from_three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(selected_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(subset_folder + \"/\" + cid_cluster_filename[:-4] + \"_selected_clusters.txt\",\"w\") as of:\n",
    "    for cluster in selected_clusters:\n",
    "        of.write(str(cluster) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (selected_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cid_cluster = {}\n",
    "for cid in cid_cluster:\n",
    "    if cid_cluster[cid] in selected_clusters:\n",
    "        cluster = selected_clusters[selected_clusters.index(cid_cluster[cid])]\n",
    "        subset_cid_cluster[cid] = cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subset_cid_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reassign_cluster_id(subset_cid_cluster,cluster_distance=None,output_path=subset_folder,addon=\"_subset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subset_cid_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cid_cluster = cid_cluster_file(subset_folder + cid_cluster_filename[:-4] + \"_subset.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_found_cid_smiles = write_smiles_cluster_file(cid_smiles_file,subset_cid_cluster,\"smiles_cluster_subset_sanitized_\" + str(distance_threshold) + \".txt\",subset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "bert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
