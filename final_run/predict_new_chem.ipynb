{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import sys\n",
    "import random\n",
    "import string\n",
    "import tqdm\n",
    "import json\n",
    "import time\n",
    "import sqlite3\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit import RDLogger\n",
    "\n",
    "from SmilesPE.pretokenizer import atomwise_tokenizer\n",
    "from SmilesPE.pretokenizer import kmer_tokenizer\n",
    "from SmilesPE.spe2vec import Corpus\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "#from utils import *\n",
    "import torch\n",
    "\n",
    "sys.path.append('../supp_scripts/')\n",
    "import supp_utils as su\n",
    "\n",
    "#torch.cuda.set_device(0) #change to 0 if you only has one GPU\n",
    "# set gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device,torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_test = \"test_cids.txt\" # Format cid in each line or cid - name in each line\n",
    "\n",
    "Number_of_workers = 8\n",
    "gpu_id = 0\n",
    "if gpu_id != None:\n",
    "    device = \"cuda:\" + str(gpu_id)\n",
    "else:\n",
    "    gpu_id = 0\n",
    "\n",
    "torch.cuda.set_device(device)\n",
    "\n",
    "spe_token_path = \"pretraining_tokens.txt\"\n",
    "\n",
    "tokenization = \"SPE\"\n",
    "\n",
    "pretraining_new_wt = \"_model_clas\"\n",
    "batch_size = 64\n",
    "\n",
    "parameter_filename = \"parameters.json\"\n",
    "parameter_file = open(parameter_filename)\n",
    "parameters = json.load(parameter_file)\n",
    "parameter_file.close()\n",
    "run_folder = parameters[\"run_folder\"]\n",
    "model_path = run_folder + \"/models/\"\n",
    "function_file_qcutoff = \"../data/preprocessed_data/protein_function_\" + str(run_folder.split(\"_\")[-1]) + \"_qcutoff.yaml\"\n",
    "function_file_lcutoff = \"../data/preprocessed_data/protein_function_\" + str(run_folder.split(\"_\")[-1]) + \"_lcutoff.yaml\"\n",
    "cluster_distance_file = \"../data/cluster_results/cluster_distance_\" + str(run_folder.split(\"_\")[-1]) + \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# To remove rdkit warning\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read cluster function file\n",
    "with open(function_file_qcutoff, 'r') as stream:\n",
    "    protein_function_qcutoff = yaml.safe_load(stream)\n",
    "    \n",
    "with open(function_file_lcutoff, 'r') as stream:\n",
    "    protein_function_lcutoff = yaml.safe_load(stream)\n",
    "    \n",
    "cluster_distance = pd.read_csv(cluster_distance_file,header=None,names=[\"cluster1\",\"cluster2\",\"distance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading input cid file and fetching from internet\n",
    "input_cids = []\n",
    "names = []\n",
    "input_smiles = []\n",
    "\n",
    "def check_entry_type(input_entry):\n",
    "    try:\n",
    "        return (int(input_entry))\n",
    "    except:\n",
    "        return (str(input_entry))\n",
    "    \n",
    "def check_input_name(entry_split):\n",
    "    try:\n",
    "        name = entry_split[1]\n",
    "        if len(entry_split) > 2:\n",
    "            name = ' '.join(entry_split[1:])\n",
    "        return name\n",
    "    except:\n",
    "        return (\"UNK\")\n",
    "        \n",
    "for n,entry in enumerate(open(input_file_test,\"r\").readlines()):\n",
    "    check_entry_type(entry)\n",
    "    entry_split = entry.split()\n",
    "    input_entry = check_entry_type(entry_split[0])\n",
    "    \n",
    "    if type(input_entry) == int:\n",
    "        #input_cids.append(input_entry)\n",
    "        cid_smiles = su.get_smiles_from_cid(input_entry,type_smiles=\"isomeric\",get_from=\"SDF\",folder_file_name=\"\",save_output=False,remove_sdf=False)\n",
    "        input_smiles.append(cid_smiles[input_entry])\n",
    "        input_cids.append(input_entry)\n",
    "    else:\n",
    "        input_smiles.append(input_entry)\n",
    "        input_cids.append(input_entry)\n",
    "        \n",
    "    name = check_input_name(entry_split)\n",
    "    names.append(name)\n",
    "    \n",
    "test_df = pd.DataFrame([(cid,smiles) for cid,smiles in zip(input_cids,input_smiles)], columns=['CID','Smiles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid_smiles = {}\n",
    "test_dict = test_df.to_dict()\n",
    "for n in range(len(test_df)):\n",
    "    smiles =  test_dict[\"Smiles\"][n]\n",
    "    cid =  test_dict[\"CID\"][n]\n",
    "    cid_smiles[cid] = smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(yhat,y):\n",
    "    softmax = torch.exp(yhat.float())\n",
    "    prob = softmax.cpu().detach().numpy()\n",
    "    predictions = np.argmax(prob, axis=1)\n",
    "    y_truth = y.cpu().detach().numpy()\n",
    "    accuracy_check = (y_truth==predictions)\n",
    "    count = np.count_nonzero(accuracy_check)\n",
    "    accuracy = (count/len(accuracy_check))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilizing tokenizer\n",
    "if tokenization == \"SPE\":\n",
    "    MolTokenizer = su.molpmofit.MolTokenizer_spe_sos_eos\n",
    "    tok = Tokenizer(partial(MolTokenizer,token_path=spe_token_path), n_cpus=Number_of_workers, pre_rules=[], post_rules=[])\n",
    "else:\n",
    "    MolTokenizer = su.molpmofit.MolTokenizer_atomwise_sos_eos\n",
    "    tok = Tokenizer(partial(MolTokenizer), n_cpus=Number_of_workers, pre_rules=[], post_rules=[])\n",
    "\n",
    "tok = Tokenizer(partial(MolTokenizer,token_path=spe_token_path), n_cpus=Number_of_workers, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(run_folder + \"/valid_set.txt\",\"r\") as f:\n",
    "    num_classes = list(set([entry.split()[1] for entry in f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading vocab from the file\n",
    "# The file is output of the training of final model\n",
    "vocab = [vocab_token.strip() for vocab_token in open(\"text_class_vocab.txt\",\"r\").readlines()]\n",
    "vocab_class = text.transform.Vocab(vocab)\n",
    "test_data_clas = TextClasDataBunch.from_df(\"\", test_df, test_df, bs=batch_size, tokenizer=tok, \n",
    "                              chunksize=50000, text_cols='Smiles',label_cols='CID', vocab=vocab_class, max_vocab=60000,\n",
    "                                              include_bos=False,classes=[i for i in range(1,len(num_classes)+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "learner = text_classifier_learner(test_data_clas, AWD_LSTM, pretrained=False, drop_mult=0.2)\n",
    "learner.model_dir = model_path\n",
    "learner.load('_model_clas', purge=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of clusters\n",
    "cid_prediction = {}\n",
    "\n",
    "for i,cid in enumerate(cid_smiles):\n",
    "    smiles = cid_smiles[cid]\n",
    "    results = learner.predict(smiles)\n",
    "    prob = results[2].cpu().detach().numpy()\n",
    "    predictions = results[1].cpu().detach().numpy().tolist()\n",
    "    if len(names) > 0:\n",
    "        cid_prediction[cid] = {\"prediction\":predictions,\"name\":names[i],\"softmax_probability\":max(prob)}\n",
    "    else:\n",
    "        cid_prediction[cid] = {\"prediction\":predictions,\"softmax_probability\":max(prob)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distance between clusters\n",
    "predicted_clusters = []\n",
    "for cid in cid_prediction:\n",
    "    cluster = cid_prediction[cid][\"prediction\"]\n",
    "    predicted_clusters.append(cluster)\n",
    "\n",
    "cluster_distance_dicts = []\n",
    "for clust1 in predicted_clusters:\n",
    "    for clust2 in predicted_clusters:\n",
    "        if clust1 != clust2:\n",
    "            distance = cluster_distance[((cluster_distance[\"cluster1\"] == clust1) | (cluster_distance[\"cluster2\"] == clust1)) & \\\n",
    "                             ((cluster_distance[\"cluster1\"] == clust2) | (cluster_distance[\"cluster2\"] == clust2))][\"distance\"].tolist()[0]\n",
    "        else:\n",
    "            distance = 0\n",
    "        entry1 = {\"cluster1\":clust1,\"cluster2\":clust2,\"distance\":distance}\n",
    "        entry2 = {\"cluster1\":clust2,\"cluster2\":clust1,\"distance\":distance}\n",
    "        if entry1 not in cluster_distance_dicts:\n",
    "            cluster_distance_dicts.append(entry1)\n",
    "        if entry2 not in cluster_distance_dicts:\n",
    "            cluster_distance_dicts.append(entry2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distance between cids\n",
    "cid_distance_dicts = []\n",
    "for cid1 in cid_prediction:\n",
    "    for cid2 in cid_prediction:\n",
    "        clust1 = cid_prediction[cid1][\"prediction\"]\n",
    "        clust2 = cid_prediction[cid2][\"prediction\"]\n",
    "        for lists in cluster_distance_dicts:\n",
    "            try:\n",
    "                if lists['cluster1'] == clust1 and lists['cluster2'] == clust2:\n",
    "                    distance = lists[\"distance\"]\n",
    "                    cid_distance = {\"cid1\":cid1,\"cid2\":cid2,\"distance\":distance}\n",
    "                    cid_distance_dicts.append(cid_distance)\n",
    "                    break\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make distance matrix\n",
    "cid_distance_matrix = []\n",
    "for cid1 in input_cids:\n",
    "    row_list = []\n",
    "    for cid2 in input_cids:\n",
    "        for lists in cid_distance_dicts:\n",
    "            try:\n",
    "                if lists['cid1'] == cid1 and lists['cid2'] == cid2:\n",
    "                    distance = lists[\"distance\"]\n",
    "                    if distance == 0 and cid1 != cid2:\n",
    "                        distance += 0.001\n",
    "                    row_list.append(distance)\n",
    "                    break\n",
    "            except:\n",
    "                pass\n",
    "    cid_distance_matrix.append(row_list)\n",
    "dm_array = np.array(cid_distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distance between the chemicals\n",
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "def make_plot(distance_matrix,labels,figure_name=\"chemical_distance.png\"):\n",
    "    dists = squareform(distance_matrix)\n",
    "    links = linkage(dists, \"complete\")\n",
    "    ddata = dendrogram(links, labels=labels,leaf_font_size=12,orientation=\"left\") \n",
    "    for i, d in zip(ddata['icoord'], ddata['dcoord']):\n",
    "            y = 0.5 * sum(i[1:3])\n",
    "            x = d[1]\n",
    "            if x > 0.001:\n",
    "                #plt.plot(x, y, 'ro')\n",
    "                plt.annotate(\"%.3g\" % x, (x, y), xytext=(0, +12),\n",
    "                                 textcoords='offset points',\n",
    "                                 va='top', ha='center',fontsize=12)\n",
    "\n",
    "    plt.xlabel(\"Distance\",fontsize=12)\n",
    "    plt.ylabel(\"Chemicals\",fontsize=12)\n",
    "    plt.title(\"Chemical distance\",fontsize=15)#, orientation='left'\n",
    "    plt.savefig(figure_name)\n",
    "    plt.show()\n",
    "    \n",
    "make_plot(dm_array,input_cids,\"chemical_distance_cids.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If names are given, plot with names\n",
    "if len(names) > 0:\n",
    "    make_plot(dm_array,names,\"chemical_distance_names.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Club cluster prediction of same kind\n",
    "cluster_cid = {}\n",
    "for cid in cid_prediction:\n",
    "    predicted_cluster = cid_prediction[cid][\"prediction\"]\n",
    "    if predicted_cluster not in cluster_cid:\n",
    "        cluster_cid[predicted_cluster] = []\n",
    "    cluster_cid[predicted_cluster].append(cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get function of the cluster\n",
    "def get_function_from_prediction(protein_function_file):\n",
    "    for cluster in cluster_cid:\n",
    "        cids = cluster_cid[cluster]\n",
    "        print (\"CIDs = \" + str(cids)[1:-1])\n",
    "        if len(names) > 0:\n",
    "            chemical_names = []\n",
    "            for cid in cids:\n",
    "                index = input_cids.index(cid)\n",
    "                chemical_names.append(names[index])\n",
    "            print (\"Chemical names = \" + str(chemical_names)[1:-1])\n",
    "        print (\"Cluster predicted= \" + str(cluster))\n",
    "        print (\"\\nFunction\\n\")\n",
    "        for i,entry in enumerate(protein_function_file[cluster]):\n",
    "            print (str(i+1) + \".) \" + str(entry)[1:-1] + \"\\n\")\n",
    "        print (\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cid_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions and functions of the cluster with Qcutoff \n",
    "get_function_from_prediction(protein_function_qcutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_function_from_prediction(protein_function_lcutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "molpmofit",
   "language": "python",
   "name": "molpmofit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
