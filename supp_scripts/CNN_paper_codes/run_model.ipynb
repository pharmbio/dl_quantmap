{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "file='NR-AR-LBD_wholetraining.smiles.txt'\n",
    "clean_file = file[:-4] + \"_out.txt\"\n",
    "open_file = open(file,\"r\").readlines()\n",
    "\n",
    "output = open(clean_file,\"w\")\n",
    "finished_list = []\n",
    "for entry in open_file:\n",
    "    if entry.split()[0] not in finished_list:\n",
    "        finished_list.append(entry.split()[0])\n",
    "        output.write(entry.split()[0] + \" \" + entry.split()[1] + \"\\n\")\n",
    "\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Training  Dataset...\n",
      "Loading smiles:  NR-AR-LBD_wholetraining.smiles_out.txt\n",
      "(1586, 1) (1586, 1, 400, 42)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python \n",
    "# coding:utf-8\n",
    "\n",
    "import time, argparse, gc, os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "from feature import *\n",
    "import SCFPfunctions as Mf\n",
    "#import SCFPmodel as Mm\n",
    "\n",
    "# chainer v2\n",
    "'''import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import cuda, Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Reporter, report, report_scope\n",
    "from chainer import Link, Chain, ChainList, training\n",
    "from chainer.datasets import tuple_dataset\n",
    "from chainer.training import extensions'''\n",
    "\n",
    "\n",
    "xp=np\n",
    "#xp=cp\n",
    "\n",
    "print('Making Training  Dataset...')\n",
    "file = clean_file\n",
    "print('Loading smiles: ', file)\n",
    "smi = Chem.SmilesMolSupplier(file,delimiter=' ',titleLine=False)\n",
    "mols = [mol for mol in smi if mol is not None]\n",
    "\n",
    "F_list, T_list = [],[]\n",
    "for mol in mols:\n",
    "    if len(Chem.MolToSmiles(mol, kekuleSmiles=True, isomericSmiles=True)) > 400: print(\"too long mol was ignored\")\n",
    "    else:\n",
    "        F_list.append(mol_to_feature(mol,-1,400))\n",
    "        T_list.append(mol.GetProp('_Name'))\n",
    "Mf.random_list(F_list)\n",
    "Mf.random_list(T_list)\n",
    "\n",
    "data_t = xp.asarray(T_list, dtype=xp.int32).reshape(-1,1)\n",
    "data_f = xp.asarray(F_list, dtype=xp.float32).reshape(-1,1,400,lensize)\n",
    "\n",
    "dataset = (data_f,data_t)\n",
    "#train_dataset = datasets.TupleDataset(data_f, data_t) \n",
    "print(data_t.shape, data_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1586, 42, 400, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = dataset[0].T,dataset[1]\n",
    "x=np.moveaxis(x,-1,0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1427 1427 1586\n",
      "(1427, 42, 400, 1) (1427, 1) (159, 42, 400, 1) (159, 1)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(4)\n",
    "x = np.random.permutation(x)\n",
    "y = np.random.permutation(y)\n",
    "x_90 = int(x.shape[0]*0.9)\n",
    "y_90 = int(y.shape[0]*0.9)\n",
    "print (x_90,y_90,x.shape[0])\n",
    "x_train,x_test = x[:x_90],x[x_90:]\n",
    "y_train,y_test = y[:y_90],y[y_90:]\n",
    "print(x_train.shape,y_train.shape,x_test.shape,y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from os import path, getcwd, chdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc') is not None and logs.get('acc')>0.90):\n",
    "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x,y):\n",
    "    callbacks = myCallback()\n",
    "    model = tf.keras.models.Sequential([\n",
    "            # YOUR CODE STARTS HERE\n",
    "            tf.keras.layers.Conv2D(128,(3,3),activation='relu',input_shape=(42, 400, 1)),\n",
    "            tf.keras.layers.MaxPool2D((2,2)),\n",
    "            tf.keras.layers.Conv2D(256,(3,3),activation='relu'),\n",
    "            tf.keras.layers.MaxPool2D((2,2)),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(units=20, activation='relu'),\n",
    "            tf.keras.layers.Dense(units=5, activation='softmax')\n",
    "            # YOUR CODE ENDS HERE\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    # model fitting\n",
    "    history = model.fit(\n",
    "        # YOUR CODE STARTS HERE\n",
    "        x, y, epochs=20,callbacks=[callbacks]\n",
    "        # YOUR CODE ENDS HERE\n",
    "    )\n",
    "    # model fitting\n",
    "    return history.epoch, history,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45/45 [==============================] - 72s 2s/step - loss: 1.1488 - accuracy: 0.6776\n",
      "Epoch 2/20\n",
      "45/45 [==============================] - 78s 2s/step - loss: 1.0308 - accuracy: 0.6910\n",
      "Epoch 3/20\n",
      "45/45 [==============================] - 76s 2s/step - loss: 1.0186 - accuracy: 0.6903\n",
      "Epoch 4/20\n",
      "45/45 [==============================] - 86s 2s/step - loss: 0.9848 - accuracy: 0.6938\n",
      "Epoch 5/20\n",
      "45/45 [==============================] - 78s 2s/step - loss: 0.9368 - accuracy: 0.6952\n",
      "Epoch 6/20\n",
      "45/45 [==============================] - 76s 2s/step - loss: 0.8492 - accuracy: 0.7022\n",
      "Epoch 7/20\n",
      "45/45 [==============================] - 80s 2s/step - loss: 0.7787 - accuracy: 0.7239\n",
      "Epoch 8/20\n",
      "45/45 [==============================] - 81s 2s/step - loss: 0.6509 - accuracy: 0.7596\n",
      "Epoch 9/20\n",
      "45/45 [==============================] - 81s 2s/step - loss: 0.5396 - accuracy: 0.7926\n",
      "Epoch 10/20\n",
      "45/45 [==============================] - 80s 2s/step - loss: 0.4435 - accuracy: 0.8325\n",
      "Epoch 11/20\n",
      "45/45 [==============================] - 79s 2s/step - loss: 0.3576 - accuracy: 0.8633\n",
      "Epoch 12/20\n",
      "45/45 [==============================] - 81s 2s/step - loss: 0.2819 - accuracy: 0.8935\n",
      "Epoch 13/20\n",
      "45/45 [==============================] - 79s 2s/step - loss: 0.2252 - accuracy: 0.9208\n",
      "Epoch 14/20\n",
      "45/45 [==============================] - 79s 2s/step - loss: 0.1838 - accuracy: 0.9404\n",
      "Epoch 15/20\n",
      "45/45 [==============================] - 81s 2s/step - loss: 0.1665 - accuracy: 0.9432\n",
      "Epoch 16/20\n",
      "45/45 [==============================] - 80s 2s/step - loss: 0.1456 - accuracy: 0.9502\n",
      "Epoch 17/20\n",
      "45/45 [==============================] - 82s 2s/step - loss: 0.1607 - accuracy: 0.9502\n",
      "Epoch 18/20\n",
      "45/45 [==============================] - 80s 2s/step - loss: 0.1304 - accuracy: 0.9516\n",
      "Epoch 19/20\n",
      "45/45 [==============================] - 82s 2s/step - loss: 0.1182 - accuracy: 0.9615\n",
      "Epoch 20/20\n",
      "45/45 [==============================] - 81s 2s/step - loss: 0.1123 - accuracy: 0.9622\n"
     ]
    }
   ],
   "source": [
    "_, _,model = train_model(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x_test, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = tf.argmax(prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(19,), dtype=int64, numpy=array([2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2])>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#test data\n",
    "file='test_set'\n",
    "clean_file = file[:-4] + \"_out.txt\"\n",
    "open_file = open(file,\"r\").readlines()\n",
    "\n",
    "output = open(clean_file,\"w\")\n",
    "finished_list = []\n",
    "for entry in open_file:\n",
    "    if entry.split()[0] not in finished_list:\n",
    "        finished_list.append(entry.split()[0])\n",
    "        output.write(entry.split()[0] + \" \" + entry.split()[1] + \"\\n\")\n",
    "\n",
    "output.close()\n",
    "\n",
    "xp=np\n",
    "#xp=cp\n",
    "\n",
    "print('Making Training  Dataset...')\n",
    "file = clean_file\n",
    "print('Loading smiles: ', file)\n",
    "smi = Chem.SmilesMolSupplier(file,delimiter=' ',titleLine=False)\n",
    "mols = [mol for mol in smi if mol is not None]\n",
    "\n",
    "F_list, T_list = [],[]\n",
    "for mol in mols:\n",
    "    if len(Chem.MolToSmiles(mol, kekuleSmiles=True, isomericSmiles=True)) > 400: print(\"too long mol was ignored\")\n",
    "    else:\n",
    "        F_list.append(mol_to_feature(mol,-1,400))\n",
    "        T_list.append(mol.GetProp('_Name'))\n",
    "Mf.random_list(F_list)\n",
    "Mf.random_list(T_list)\n",
    "\n",
    "data_t = xp.asarray(T_list, dtype=xp.int32).reshape(-1,1)\n",
    "data_f = xp.asarray(F_list, dtype=xp.float32).reshape(-1,1,400,lensize)\n",
    "print(data_t.shape, data_f.shape)\n",
    "test_data = (data_f,data_t)\n",
    "x_test,y_test = test_data[0].T,test_data[1]\n",
    "x_test=np.moveaxis(x_test,-1,0)\n",
    "print (x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 219ms/step - loss: 5.0272 - accuracy: 0.4906\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.67577075958252, 0.1428571492433548]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
